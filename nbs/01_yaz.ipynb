{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6febe163-9721-4b15-8266-2a27e361d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb72158-9c27-4551-b03d-7d621714b399",
   "metadata": {},
   "source": [
    "# Yaz Dataset\n",
    "\n",
    "> To be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288a302-2d75-4fc4-b221-705f86345a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp loadDataYaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1e3ed-8793-4e8d-bead-c0a21bb3e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "from datasetsDynamic.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os.path import join\n",
    "import pathlib\n",
    "import pkg_resources\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d6516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createLagFeatures(data, idFeature = 'id', lagDays = range(1, 8), lagDaysArithmetic = [7, 14, 21, 28]):\n",
    "\n",
    "#     IDs = data[idFeature].unique()\n",
    "\n",
    "#     yLagPerID = list()\n",
    "\n",
    "#     # Loop over all items\n",
    "#     for ID in IDs:\n",
    "#         dataID = data[data[idFeature] == ID]\n",
    "\n",
    "#         y = dataID.demand\n",
    "\n",
    "#         # Create lag features of y (demand) with time windows of 7 days\n",
    "#         lagDemands = [y.shift(i) for i in lagDays]\n",
    "#         yLag = pd.concat(lagDemands, axis = 1)\n",
    "\n",
    "#         yLag.columns = ['demand_lag_' + str(i) for i in range(1, 8)]\n",
    "\n",
    "#         #---\n",
    "\n",
    "#         yLagArithmeticList = list()\n",
    "#         # Create lagged mean, max, min, variance, sum of last 7, 14, 21 and 28 days without current day\n",
    "#         for i in lagDaysArithmetic:\n",
    "\n",
    "#             # remove current day\n",
    "#             yMod2 = y.iloc[1:]\n",
    "#             yMod = y.shift(1)\n",
    "\n",
    "#             # Compute lagged mean, max, min, variance, sum\n",
    "#             yLagMean = yMod.rolling(i).mean()\n",
    "#             yLagMean.name = 'demand_lag_mean_' + str(i)\n",
    "\n",
    "#             yLagMax = yMod.rolling(i).max()\n",
    "#             yLagMax.name = 'demand_lag_max_' + str(i)\n",
    "\n",
    "#             yLagMin = yMod.rolling(i).min()\n",
    "#             yLagMin.name = 'demand_lag_min_' + str(i)\n",
    "\n",
    "#             yLagVar = yMod.rolling(i).var()\n",
    "#             yLagVar.name = 'demand_lag_var_' + str(i)\n",
    "\n",
    "#             yLagSum = yMod.rolling(i).sum()\n",
    "#             yLagSum.name = 'demand_lag_sum_' + str(i)\n",
    "\n",
    "#             yLagArithmetic = pd.concat([yLagMean, yLagMax, yLagMin, yLagVar, yLagSum], axis = 1)\n",
    "#             yLagArithmeticList.append(yLagArithmetic)\n",
    "\n",
    "#         yLagArithmeticAll = pd.concat(yLagArithmeticList, axis = 1)\n",
    "\n",
    "#         # Add lag features to list\n",
    "#         yLagAll = pd.concat([yLag, yLagArithmeticAll], axis = 1)\n",
    "#         yLagPerID.append(yLagAll)\n",
    "\n",
    "#     # Concatenate lag features of all items\n",
    "#     yLagAllIDs = pd.concat(yLagPerID, axis = 0)\n",
    "\n",
    "#     # Add lag features to data\n",
    "#     dataWithLags = pd.concat([data, yLagAllIDs], axis = 1)\n",
    "\n",
    "#     return dataWithLags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def loadDataYaz(testDays = 7, daysToCut = 0, normalizeDemand = True, unstacked = True, returnXY = True):\n",
    "\n",
    "    # LOAD DATA\n",
    "    dataPath = pkg_resources.resource_stream(__name__, 'datasets/dataYaz_unprocessed.csv')\n",
    "    data = pd.read_csv(dataPath)\n",
    "    # dataPath = \"/home/kagu/datasetsDynamic/datasetsDynamic/datasets/dataYaz_unprocessed.csv\"\n",
    "    # data = pd.read_csv(dataPath)\n",
    "\n",
    "    # DAY INDEX\n",
    "    data = data.reset_index().rename(columns = {'index': 'dayIndex'})\n",
    "    data['dayIndex'] = data.dayIndex\n",
    "\n",
    "    # SEPARATE DEMAND OF DIFFERENT ITEMS\n",
    "    X = data.iloc[:, 0:11]\n",
    "    y = data.iloc[:, 12:]\n",
    "\n",
    "    dataList = list()\n",
    "    for col in y.columns:\n",
    "        X_temp = X\n",
    "        X_temp[\"item\"] = col\n",
    "        y_temp = y[col]\n",
    "        data_temp = pd.concat([X_temp, y_temp], axis=1)\n",
    "        data_temp.rename(columns={col: \"demand\"}, inplace=True)\n",
    "        dataList.append(data_temp)\n",
    "\n",
    "    data = pd.concat(dataList, axis = 0)\n",
    "\n",
    "    #---\n",
    "\n",
    "    # ID FEATURE AND SORTING\n",
    "    data['id'] = data['item']\n",
    "    data = data.sort_values(by = ['id', 'dayIndex'], axis = 0).reset_index(drop = True)\n",
    "\n",
    "    #---\n",
    "\n",
    "    # CUT DAYS DEPENDING ON DAYSTOCUT\n",
    "    cutOffDate = data.dayIndex.max() - daysToCut\n",
    "    data = data[data['dayIndex'] <= cutOffDate].reset_index(drop = True)\n",
    "\n",
    "    #---\n",
    "\n",
    "    # LABEL\n",
    "    if isinstance(testDays, int):\n",
    "        nDaysTest = testDays\n",
    "    else:\n",
    "        tsSizes = data.groupby(['id']).size()\n",
    "        nDaysTest = int(tsSizes.iloc[0] * testDays)\n",
    "\n",
    "    cutoffDateTest = data.dayIndex.max() - nDaysTest\n",
    "    data['label'] = ['train' if data.dayIndex.iloc[i] <= cutoffDateTest else 'test' for i in range(data.shape[0])]    \n",
    "\n",
    "    #---\n",
    "\n",
    "    # NORMALIZE DEMAND\n",
    "    if normalizeDemand:\n",
    "        scalingData = data[data.label == 'train'].groupby('id')['demand'].agg('max').reset_index()\n",
    "        scalingData.rename(columns = {'demand': 'scalingValue'}, inplace = True)\n",
    "        data = pd.merge(data, scalingData, on = 'id')\n",
    "\n",
    "        data['demand'] = data.demand / data.scalingValue\n",
    "    else:\n",
    "        data['scalingValue'] = 1\n",
    "\n",
    "    #---\n",
    "\n",
    "    # DEMAND LAG FEATURES\n",
    "    data = createLagFeatures(data = data, \n",
    "                            idFeature = 'id',\n",
    "                            lagDays = range(1, 8), \n",
    "                            lagDaysArithmetic = [7, 14, 21, 28])\n",
    "\n",
    "    #---\n",
    " \n",
    "    # CREATE UNSTACKED MULTIDIMENSIONAL DEMAND VECTOR IF DESIRED\n",
    "    \n",
    "    X = data.drop(['demand'], axis = 1, inplace = False)\n",
    "    y = data[['demand']]\n",
    "\n",
    "    if unstacked:\n",
    "        colsDemand = [column for column in X.columns if 'demand_' in column]\n",
    "        colsOther = [column for column in X.columns if not 'demand_' in column]\n",
    "        \n",
    "        generalData = data[colsOther][data['id'] == X['id'][0]].reset_index(drop = True).drop(['id', 'scalingValue'], axis = 1)\n",
    "        \n",
    "        XList = list()\n",
    "        yList = list()\n",
    "        scalingValueList = list()\n",
    "        \n",
    "        XList.append(generalData)\n",
    "\n",
    "        for item in np.unique(X['id']):\n",
    "            XItem = X[X['id'] == item].reset_index(drop = True)\n",
    "            yItem = y[X['id'] == item].reset_index(drop = True)\n",
    "\n",
    "            newColNames = {col: col + '_' + item for col in colsDemand}\n",
    "            \n",
    "            XToAdd = XItem[colsDemand].rename(columns = newColNames)\n",
    "            yToAdd = yItem.rename(columns = {'demand': 'demand_' + item})\n",
    "            scalingValueToAdd = XItem[['scalingValue']].rename(columns = {'scalingValue': 'scalingValue_' + item})\n",
    "            \n",
    "            XList.append(XToAdd)\n",
    "            yList.append(yToAdd)\n",
    "            scalingValueList.append(scalingValueToAdd)\n",
    "            \n",
    "        X = pd.concat(XList, axis = 1)\n",
    "        y = pd.concat(yList, axis = 1)\n",
    "        scalingValues = pd.concat(scalingValueList, axis = 1)\n",
    "        \n",
    "        X = pd.concat([X, scalingValues], axis = 1)\n",
    "\n",
    "    #---\n",
    "\n",
    "    # DATE DUMMY VARIABLES\n",
    "    X['year'] = X['year'].apply(lambda x: str(int(x)))\n",
    "\n",
    "    dateDummies = pd.concat([pd.get_dummies(X.weekday, prefix = 'weekday'), \n",
    "                             pd.get_dummies(X.month, prefix = 'month'), \n",
    "                             pd.get_dummies(X.year, prefix = 'year')], axis = 1)\n",
    "\n",
    "    itemDummies = pd.get_dummies(X.item, prefix = 'item')\n",
    "\n",
    "    X = pd.concat([X, dateDummies, itemDummies], axis = 1).drop(['weekday', 'month', 'year', 'item'], axis = 1)\n",
    "\n",
    "    #---\n",
    "\n",
    "    # SPLIT INTO TRAIN AND TEST DATA\n",
    "    if unstacked:\n",
    "        XArray = np.array(X.drop(['label'], axis = 1))\n",
    "        yArray = np.array(y)          \n",
    "    else:\n",
    "        XArray = np.array(X.drop(['label', 'id'], axis = 1))\n",
    "        yArray = np.ravel(y)    \n",
    "\n",
    "\n",
    "    XTrain = XArray[X['label'] == 'train']\n",
    "    yTrain = yArray[X['label'] == 'train']\n",
    "\n",
    "    XTest = XArray[X['label'] == 'test']\n",
    "    yTest = yArray[X['label'] == 'test']\n",
    "\n",
    "    data = pd.concat([y, X], axis = 1)\n",
    "\n",
    "    #---\n",
    "\n",
    "    if not normalizeDemand:\n",
    "        \n",
    "        if unstacked:\n",
    "            colsScalingValue = [column for column in X.columns if 'scalingValue' in column]\n",
    "            data.drop(colsScalingValue, axis = 1)\n",
    "            X.drop(colsScalingValue, axis = 1)\n",
    "            \n",
    "        else:\n",
    "            data = data.drop(['scalingValue'], axis = 1)\n",
    "            X = X.drop(['scalingValue'], axis = 1)\n",
    "\n",
    "    if returnXY:\n",
    "        return data, XTrain, yTrain, XTest, yTest\n",
    "    else:\n",
    "        return data    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4ac80-295e-4787-b587-68517b1be286",
   "metadata": {},
   "source": [
    "## Load and Preprocess Yaz Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852ce5e-24fd-4f8d-bc9b-3c7479d8be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# def loadDataYaz(testDays = 28, returnXY = True, daysToCut = 0, unstacked = False, disable_progressbar = False):\n",
    "    \n",
    "#     # LOAD DATA\n",
    "#     dataPath = pkg_resources.resource_stream(__name__, 'datasets/dataYaz_unprocessed.csv')\n",
    "#     data = pd.read_csv(dataPath)\n",
    "    \n",
    "#     #---\n",
    "    \n",
    "#     # DAY INDEX\n",
    "#     data = data.reset_index().rename(columns = {'index': 'dayIndex'})\n",
    "#     data['dayIndex'] = data.dayIndex\n",
    "\n",
    "#     #---\n",
    "    \n",
    "#     # SEPARATE DEMAND OF DIFFERENT ITEMS\n",
    "#     X = data.iloc[:, 0:11]\n",
    "#     y = data.iloc[:, 12:]\n",
    "\n",
    "#     dataList = list()\n",
    "#     for col in y.columns:\n",
    "#         X_temp = X\n",
    "#         X_temp[\"item\"] = col\n",
    "#         y_temp = y[col]\n",
    "#         data_temp = pd.concat([X_temp, y_temp], axis=1)\n",
    "#         data_temp.rename(columns={col: \"demand\"}, inplace=True)\n",
    "#         dataList.append(data_temp)\n",
    "\n",
    "#     data = pd.concat(dataList, axis = 0)\n",
    "\n",
    "#     #---\n",
    "    \n",
    "#     # ID FEATURE AND SORTING\n",
    "#     data['id'] = data['item']\n",
    "#     data = data.sort_values(by = ['id', 'dayIndex'], axis = 0).reset_index(drop = True)\n",
    "\n",
    "#     #---\n",
    "\n",
    "#     # CUT DAYS DEPENDING ON DAYSTOCUT\n",
    "#     cutOffDate = data.dayIndex.max() - daysToCut\n",
    "#     data = data[data['dayIndex'] <= cutOffDate].reset_index(drop = True)\n",
    "    \n",
    "#     #---\n",
    "    \n",
    "#     # LABEL\n",
    "#     if isinstance(testDays, int):\n",
    "#         nDaysTest = testDays\n",
    "#     else:\n",
    "#         tsSizes = data.groupby(['id']).size()\n",
    "#         nDaysTest = int(tsSizes.iloc[0] * testDays)\n",
    "\n",
    "#     cutoffDateTest = data.dayIndex.max() - nDaysTest\n",
    "#     data['label'] = ['train' if data.dayIndex.iloc[i] <= cutoffDateTest else 'test' for i in range(data.shape[0])]    \n",
    "    \n",
    "#     #---\n",
    "    \n",
    "#     # NORMALIZE DEMAND\n",
    "#     scalingData = data[data.label == 'train'].groupby('id')['demand'].agg('max').reset_index()\n",
    "#     scalingData.rename(columns = {'demand': 'scalingValue'}, inplace = True)\n",
    "#     data = pd.merge(data, scalingData, on = 'id')\n",
    "\n",
    "#     data['demand'] = data.demand / data.scalingValue\n",
    "\n",
    "#     #---\n",
    "\n",
    "#     # DEMAND LAG FEATURES\n",
    "#     y = pd.DataFrame(data['demand'])\n",
    "#     X = data.drop(columns = ['demand'])\n",
    "\n",
    "#     # set lag features\n",
    "#     fc_parameters = MinimalFCParameters()\n",
    "\n",
    "#     # delete length features\n",
    "#     del fc_parameters['length']\n",
    "\n",
    "#     # create lag features\n",
    "#     X, y = add_lag_features(X = X, \n",
    "#                             y = y, \n",
    "#                             column_id = ['id'], \n",
    "#                             column_sort = 'dayIndex', \n",
    "#                             feature_dict = fc_parameters, \n",
    "#                             time_windows = [(7, 7), (14, 14), (28, 28)],\n",
    "#                             n_jobs = 6, \n",
    "#                             disable_progressbar = False)\n",
    "    \n",
    "#     #---\n",
    "\n",
    "#     # CREATE UNSTACKED MULTIDIMENSIONAL DEMAND VECTOR IF DESIRED\n",
    "#     if unstacked:\n",
    "#         colsDemand = [column for column in X.columns if 'demand__' in column]\n",
    "#         colsOther = [column for column in X.columns if not 'demand__' in column]\n",
    "        \n",
    "#         generalData = X[colsOther][X['id'] == X['id'][0]].reset_index(drop = True).drop(['id', 'scalingValue'], axis = 1)\n",
    "        \n",
    "#         XList = list()\n",
    "#         yList = list()\n",
    "#         scalingValueList = list()\n",
    "        \n",
    "#         XList.append(generalData)\n",
    "\n",
    "#         for item in np.unique(X['id']):\n",
    "#             XItem = X[X['id'] == item].reset_index(drop = True)\n",
    "#             yItem = y[X['id'] == item].reset_index(drop = True)\n",
    "\n",
    "#             newColNames = {col: col + '_' + item for col in colsDemand}\n",
    "            \n",
    "#             XToAdd = XItem[colsDemand].rename(columns = newColNames)\n",
    "#             yToAdd = yItem.rename(columns = {'demand': 'demand_' + item})\n",
    "#             scalingValueToAdd = XItem[['scalingValue']].rename(columns = {'scalingValue': 'scalingValue_' + item})\n",
    "            \n",
    "#             XList.append(XToAdd)\n",
    "#             yList.append(yToAdd)\n",
    "#             scalingValueList.append(scalingValueToAdd)\n",
    "            \n",
    "#         X = pd.concat(XList, axis = 1)\n",
    "#         y = pd.concat(yList, axis = 1)\n",
    "#         scalingValues = pd.concat(scalingValueList, axis = 1)\n",
    "        \n",
    "#         X = pd.concat([X, scalingValues], axis = 1)\n",
    "\n",
    "#     #---\n",
    "    \n",
    "#     # DATE DUMMY VARIABLES\n",
    "#     X['year'] = X['year'].apply(lambda x: str(int(x)))\n",
    "\n",
    "#     X = pd.concat([X, \n",
    "#                   pd.get_dummies(X.weekday, prefix = 'weekday'), \n",
    "#                   pd.get_dummies(X.month, prefix = 'month'), \n",
    "#                   pd.get_dummies(X.year, prefix = 'year')], axis = 1).drop(['weekday', 'month', 'year'], axis = 1)\n",
    "\n",
    "#     X = pd.concat([X, pd.get_dummies(X.item, prefix = 'item')], axis = 1).drop(['item'], axis = 1)\n",
    "\n",
    "#     #---\n",
    "    \n",
    "#     # SPLIT INTO TRAIN AND TEST DATA\n",
    "#     data = pd.concat([y, X], axis = 1)   \n",
    "    \n",
    "#     if unstacked:\n",
    "#         XArray = np.array(X.drop(['label'], axis = 1))\n",
    "#         yArray = np.array(y)           \n",
    "#     else:\n",
    "#         XArray = np.array(X.drop(['label', 'id'], axis = 1))\n",
    "#         yArray = np.ravel(y)    \n",
    "    \n",
    "#     XTrain = XArray[data['label'] == 'train']\n",
    "#     yTrain = yArray[data['label'] == 'train']\n",
    "\n",
    "#     XTest = XArray[data['label'] == 'test']\n",
    "#     yTest = yArray[data['label'] == 'test']\n",
    "\n",
    "#     #---\n",
    "\n",
    "#     if returnXY:\n",
    "#         return data, XTrain, yTrain, XTest, yTest\n",
    "#     else:\n",
    "#         return data    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba747cf3-2c08-405b-8f1a-ab7595d5e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasets",
   "language": "python",
   "name": "datasets"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
