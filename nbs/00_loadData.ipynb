{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6febe163-9721-4b15-8266-2a27e361d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb72158-9c27-4551-b03d-7d621714b399",
   "metadata": {},
   "source": [
    "# Load Datasets\n",
    "\n",
    "> The functions in this notebook load datasets that can be used to test the presented procedures of this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288a302-2d75-4fc4-b221-705f86345a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp loadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1e3ed-8793-4e8d-bead-c0a21bb3e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from os.path import join\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "from tsfresh import extract_features\n",
    "import pathlib\n",
    "\n",
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4ac80-295e-4787-b587-68517b1be286",
   "metadata": {},
   "source": [
    "## Yaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666477b-b4a2-4ab5-957a-f8531cddb8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def loadDataYaz(testDays = 28, returnXY = True, daysToCut = 0):\n",
    "    \n",
    "#     currentFile = __file__\n",
    "#     scriptPath = os.path.realpath(currentFile)  # /home/user/test/my_script.py\n",
    "#     dirPath = os.path.dirname(scriptPath)  # /home/user/test\n",
    "    \n",
    "#     dataDirPath = join(dirPath, 'datasets')\n",
    "#     dataPath = join(dataDirPath, 'dataYaz.csv')\n",
    "    \n",
    "    dataPath = pkg_resources.resource_stream(__name__, 'datasets/dataYaz.csv')\n",
    "    data = pd.read_csv(dataPath)\n",
    "    \n",
    "    # Cutting away daysToCut-many days at end of data: Useful for evaluating\n",
    "    # data in a rolled manner\n",
    "    cutOffDate = data.dayIndex.max() - daysToCut\n",
    "    data = data[data['dayIndex'] <= cutOffDate].reset_index(drop = True)\n",
    "    \n",
    "    # Label\n",
    "    if isinstance(testDays, int):\n",
    "        nDaysTest = testDays\n",
    "    else:\n",
    "        tsSizes = data.groupby(['id']).size()\n",
    "        nDaysTest = int(tsSizes.iloc[0] * testDays)\n",
    "        \n",
    "    cutoffDateTest = data.dayIndex.max() - nDaysTest\n",
    "    data['label'] = ['train' if data.dayIndex.iloc[i] <= cutoffDateTest else 'test' for i in range(data.shape[0])]    \n",
    "\n",
    "    # Normalize Demand\n",
    "    scalingData = data[data.label == 'train'].groupby('id')['demand'].agg('max').reset_index()\n",
    "    scalingData.rename(columns = {'demand': 'scalingValue'}, inplace = True)\n",
    "    data = pd.merge(data, scalingData, on = 'id')\n",
    "\n",
    "    data['demand'] = data.demand / data.scalingValue\n",
    "\n",
    "    #---\n",
    "\n",
    "    # Add lag features\n",
    "    y = pd.DataFrame(data['demand'])\n",
    "    X = data.drop(columns = ['demand'])\n",
    "\n",
    "    # set lag features\n",
    "    fc_parameters = MinimalFCParameters()\n",
    "\n",
    "    # delete length features\n",
    "    del fc_parameters['length']\n",
    "\n",
    "    # create lag features\n",
    "    X, y = add_lag_features(X = X, \n",
    "                            y = y, \n",
    "                            column_id = ['id'], \n",
    "                            column_sort = 'dayIndex', \n",
    "                            feature_dict = fc_parameters, \n",
    "                            time_windows = [(7, 7), (14, 14), (28, 28)])\n",
    "    \n",
    "    data = pd.concat([y, X], axis = 1)\n",
    "                      \n",
    "    # Turn y from Series or dataframe to flatted array\n",
    "    y = np.ravel(y)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    X = np.array(data.drop(['demand', 'label', 'id'], axis = 1))\n",
    "    \n",
    "    XTrain = X[data['label'] == 'train']\n",
    "    yTrain = y[data['label'] == 'train']\n",
    "    \n",
    "    XTest = X[data['label'] == 'test']\n",
    "    yTest = y[data['label'] == 'test']\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    if returnXY:\n",
    "        return data, XTrain, yTrain, XTest, yTest\n",
    "    else:\n",
    "        return data    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a9c2c-9dba-47f6-9da1-5bdc78fe505c",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf68ed-a09f-4d7a-8e01-3bc0a5b24bb6",
   "metadata": {},
   "source": [
    "### Add lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c543ff14-fa9f-4c32-887c-87a820357428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def add_lag_features(X, y, column_id, column_sort, feature_dict, time_windows):\n",
    "    \"\"\"\n",
    "    Create lag features for y and add them to X\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X: pandas.DataFrame \n",
    "    feature matrix to which TS features are added.\n",
    "    y: pandas.DataFrame, \n",
    "    time series to compute the features for.\n",
    "    column_id: list, \n",
    "    list of column names to group by, e.g. [\"shop\",\"product\"]. If set to None, \n",
    "    either there should be nothing to groupby or each group should be \n",
    "    represented by a separate target column in y. \n",
    "    column_sort: str,\n",
    "    column name used to sort the DataFrame. If None, will be filled by an \n",
    "    increasing number, meaning that the order of the passed dataframes are used \n",
    "    as “time” for the time series.\n",
    "    feature_dict: dict,\n",
    "    dictionary containing feature calculator names with the corresponding \n",
    "    parameters\n",
    "    time_windows : list of tuples, \n",
    "    each tuple (min_timeshift, max_timeshift), represents the time shifts for \n",
    "    ech time windows to comupute e.g. [(7,7),(1,14)] for two time windos \n",
    "    a) time window with a fix size of 7 and b) time window that starts with size\n",
    "    1 and increases up to 14. Then shifts by 1 for each step. \n",
    "    \"\"\"\n",
    "\n",
    "    if column_id == None:\n",
    "        X['id'] = 1\n",
    "\n",
    "    else:\n",
    "        X['id'] = X[column_id].astype(str).agg('_'.join, axis = 1)\n",
    "\n",
    "    if column_sort == None:\n",
    "        X['time'] = range(X.shape[0])  \n",
    "\n",
    "    else:\n",
    "        X[\"time\"] = X[column_sort].copy()\n",
    "    \n",
    "    y = pd.concat([y, X[['id', 'time']]], axis = 1)\n",
    "    X = X.set_index(['id', 'time'])\n",
    "  \n",
    "    for window in time_windows:\n",
    "        \n",
    "        # create time series for given time window \n",
    "        df_rolled = roll_time_series(y, \n",
    "                                     column_id = \"id\", \n",
    "                                     column_sort = \"time\", \n",
    "                                     min_timeshift = window[0]-1, \n",
    "                                     max_timeshift = window[1]-1,\n",
    "                                     n_jobs = 6,\n",
    "                                     disable_progressbar = True)\n",
    "        \n",
    "        df_rolled['id'] = df_rolled['id'].apply(lambda x: (x[0], x[1] + 1))\n",
    "\n",
    "        # create lag features for given time window \n",
    "        df_features = extract_features(df_rolled, \n",
    "                                       column_id = \"id\", \n",
    "                                       column_sort = \"time\",\n",
    "                                       default_fc_parameters = feature_dict,\n",
    "                                       n_jobs = 6,\n",
    "                                       disable_progressbar = True)\n",
    "\n",
    "        # Add time window to feature name for clarification \n",
    "        feature_names = df_features.columns.to_list()\n",
    "        feature_names = [name + \"_\" + str(window[1]) for name in feature_names]\n",
    "        df_features.columns = feature_names\n",
    "        \n",
    "        # add features for given time window to feature matrix temp\n",
    "        X = pd.concat([X, df_features], axis = 1)\n",
    "    \n",
    "    y = y.set_index(['id', 'time'])\n",
    "    y_column_names = y.columns.to_list()\n",
    "\n",
    "    df = pd.concat([X, y],axis = 1)\n",
    "    df = df.dropna()\n",
    "    df.index.names = names = ['id', 'time']\n",
    "    df = df.reset_index(drop = False, inplace = False).drop(['time'], axis = 1, inplace = False)\n",
    "\n",
    "    y = df[y_column_names]\n",
    "    X = df.drop(y_column_names, axis = 1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9301ffb7-77e3-4493-b3e3-874d54a397c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba747cf3-2c08-405b-8f1a-ab7595d5e933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
